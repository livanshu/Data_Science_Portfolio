{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_Results.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIRY/mHUxdxvVb6HmHkh1f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/livanshu/Data_Science_Portfolio/blob/main/Projects/Automatic%20Sentiment%20Analysis/SentimentAnalysis_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtLyeL40M71u"
      },
      "source": [
        "# Accuracy on test set\n",
        "\n",
        "*part of sentiment_analysis/main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFnCynilM3WP"
      },
      "source": [
        "print(\"Pegasos\")\n",
        "best_classifier = pegasos\n",
        "best_T, best_L = 25, 0.01\n",
        "train_accu, test_accu = classifier_accuracy(best_classifier, train_bow_features, test_bow_features,\n",
        "                                            train_labels, test_labels, T=best_T, L=best_L)\n",
        "print(train_accu, test_accu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NruelxAuNGoV"
      },
      "source": [
        "Pegasos\n",
        "\n",
        "\n",
        "train_accu = 0.9185,\n",
        "test_accu  = 0.802\n",
        "\n",
        "\n",
        "# The most explanatory unigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlwksPC9NGTg"
      },
      "source": [
        "best_theta, best_theta_0 = best_classifier(train_bow_features, train_labels, T=best_T, L=best_L)\n",
        "wordlist = [word for (idx, word) in sorted(zip(dictionary.values(), dictionary.keys()))]\n",
        "sorted_word_features = utils.most_explanatory_word(best_theta, wordlist)\n",
        "print(\"Most Explanatory Word Features:\")\n",
        "print(sorted_word_features[:10])\n",
        "\n",
        "print(\"Most impactful in predicting negative labels:\")\n",
        "print(sorted_word_features[:-11:-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUAvy6hTNlkl"
      },
      "source": [
        "Most Explanatory Word Features:\n",
        "\n",
        "\n",
        "['delicious', 'great', '!', 'best', 'perfect', 'loves', 'wonderful', 'glad', 'love', 'quickly']\n",
        "\n",
        "\n",
        "Most impactful in predicting negative labels:\n",
        "\n",
        "\n",
        "['disappointed', 'bad', 'not', 'however', 'but', 'unfortunately', 'awful', 'money', 'ok', '$']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Feature Engineering\n",
        "\n",
        "\n",
        "Remove Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz_Um2HKN9Qi"
      },
      "source": [
        "with open(\"sentiment_analysis/stopwords.txt\") as f:\n",
        "  stop_words = re.findall(r'\\w+', f.read())\n",
        "dictionary_rest = p1.bag_of_words(train_texts, stop_words=stop_words)\n",
        "train_features_rest = p1.extract_bow_feature_vectors(train_texts, dictionary_rest)\n",
        "val_features_rest = p1.extract_bow_feature_vectors(val_texts, dictionary_rest)\n",
        "test_features_rest = p1.extract_bow_feature_vectors(test_texts, dictionary_rest)\n",
        "\n",
        "print(\"Accuracy on the test set\")\n",
        "train_accu, test_accu = classifier_accuracy(best_classifier, train_features_rest, test_features_rest,\n",
        "                                            train_labels, test_labels, T=best_T, L=best_L)\n",
        "print(train_accu, test_accu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAKzAFYOQdD"
      },
      "source": [
        "Accuracy on the test set\n",
        "\n",
        "\n",
        "0.91575, 0.808\n",
        "\n",
        "\n",
        "# Change binary features to counts feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBgQN3k9OYas"
      },
      "source": [
        "train_features_count = p1.extract_bow_feature_vectors(train_texts, dictionary_rest, binary=False)\n",
        "val_features_count = p1.extract_bow_feature_vectors(val_texts, dictionary_rest, binary=False)\n",
        "test_features_count = p1.extract_bow_feature_vectors(test_texts, dictionary_rest, binary=False)\n",
        "\n",
        "print(\"Accuracy on the test set\")\n",
        "train_accu, test_accu = classifier_accuracy(best_classifier, train_features_count, test_features_count,\n",
        "                                            train_labels, test_labels, T=best_T, L=best_L)\n",
        "print(train_accu, test_accu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBym55gcOmM0"
      },
      "source": [
        "Accuracy on the test set\n",
        "\n",
        "\n",
        "0.89275, 0.77"
      ]
    }
  ]
}