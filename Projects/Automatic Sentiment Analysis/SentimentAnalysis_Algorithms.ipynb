{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_Algorithms.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTcFzLddFw9OPdYL0tvShC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/livanshu/Data_Science_Portfolio/blob/main/Projects/Automatic%20Sentiment%20Analysis/SentimentAnalysis_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_HC1Wuaos2C"
      },
      "source": [
        "## Project - Automatic Sentiment Analysis using Perceptron, Average Perceptron and Pegasos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XzyDHZOorzj"
      },
      "source": [
        "import numpy as np\n",
        "import numpy.testing as npt\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF7cRVsCpE0z"
      },
      "source": [
        "# 1. Hinge Loss\n",
        "In this project, I implemented linear classifiers beginning with the Perceptron algorithm. I began by writing the loss function, a hinge-loss function. For this function, given are the parameters of your model θ and θo. \n",
        "\n",
        "Additionally, a feature matrix in which the rows are feature vectors and the columns are individual features, and a vector of labels representing the actual sentiment of the corresponding feature vector.\n",
        "\n",
        "### 1.1 Loss on one data sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KecW4-j0pEG-"
      },
      "source": [
        "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
        "    \"\"\"\n",
        "    Finds the hinge loss on a single data point given specific classification\n",
        "    parameters.\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing the given data point.\n",
        "        label - A real valued number, the correct classification of the data\n",
        "            point.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "\n",
        "    Returns: A real number representing the hinge loss associated with the\n",
        "    given data point and parameters.\n",
        "    \"\"\"\n",
        "    if label * (np.dot(feature_vector, theta) + theta_0) >= 1:\n",
        "        hinge_loss = 0\n",
        "    else:\n",
        "        hinge_loss = 1 - label * (np.dot(feature_vector, theta) + theta_0)\n",
        "    return hinge_loss\n",
        "    \n",
        "    raise NotImplementedError\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BekTsrGtqOxj"
      },
      "source": [
        "### 1.2 Complete Hinge loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8q6ig7RqO9A"
      },
      "source": [
        "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
        "    \"\"\"\n",
        "    Finds the total hinge loss on a set of data given specific classification\n",
        "    parameters.\n",
        "\n",
        "    Args:\n",
        "        feature_matrix - A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "\n",
        "    Returns: A real number representing the hinge loss associated with the\n",
        "    given dataset and parameters. This number should be the average hinge\n",
        "    loss across all of the points in the feature matrix.\n",
        "    \"\"\"\n",
        "    total_hinge_loss = np.array([])\n",
        "    for point, row_number in zip(feature_matrix, range(np.size(feature_matrix, 0))):\n",
        "        total_hinge_loss = np.append(total_hinge_loss,\n",
        "                                     hinge_loss_single(point,\n",
        "                                                       labels[row_number],\n",
        "                                                       theta, theta_0))\n",
        "    hinge_loss_full_value = np.average(total_hinge_loss)\n",
        "    return hinge_loss_full_value\n",
        "    \n",
        "    raise NotImplementedError\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5cxi46kqaAq"
      },
      "source": [
        "## 2. Perceptron Algorithm\n",
        "\n",
        "### 2.1 Perceptron Single Step Update\n",
        "\n",
        "It is single step update for the perceptron algorithm (implemented with 0−1 loss). Given are the feature vector as an array of numbers, the current θ and θo parameters, and the correct label of the feature vector. The function should return a tuple in which the first element is the correctly updated value of θ and the second element is the correctly updated value of θo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siTWCJigqZzb"
      },
      "source": [
        "def perceptron_single_step_update(\n",
        "        feature_vector,\n",
        "        label,\n",
        "        current_theta,\n",
        "        current_theta_0):\n",
        "    \"\"\"\n",
        "    Properly updates the classification parameter, theta and theta_0, on a\n",
        "    single step of the perceptron algorithm.\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing a single data point.\n",
        "        label - The correct classification of the feature vector.\n",
        "        current_theta - The current theta being used by the perceptron\n",
        "            algorithm before this update.\n",
        "        current_theta_0 - The current theta_0 being used by the perceptron\n",
        "            algorithm before this update.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta after the current update has completed and the second element is a\n",
        "    real valued number with the value of theta_0 after the current updated has\n",
        "    completed.\n",
        "    \"\"\"\n",
        "    if label * (np.dot(feature_vector, current_theta) + current_theta_0) <= 0:\n",
        "        theta_after_update = current_theta + label * feature_vector\n",
        "        theta_0_after_update = current_theta_0 + label\n",
        "        return theta_after_update, theta_0_after_update\n",
        "    else:\n",
        "        pass\n",
        "        return current_theta, current_theta_0\n",
        "\n",
        "    raise NotImplementedError\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAFC81TUrPOf"
      },
      "source": [
        "### 2.2 Full Perceptron\n",
        "\n",
        "To implement the full perceptron algorithm. Given the same feature matrix and labels array as you were given in The Complete Hinge Loss. Given T, the maximum number of times that you should iterate through the feature matrix before terminating the algorithm. Initialize θ and θo to zero. This function should return a tuple in which the first element is the final value of θ and the second element is the value of θo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybZhWbsFrO_r"
      },
      "source": [
        "def perceptron(feature_matrix, labels, T):\n",
        "    \"\"\"\n",
        "    Runs the full perceptron algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
        "\n",
        "    Args:\n",
        "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the perceptron algorithm\n",
        "            should iterate through the feature matrix.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta, the linear classification parameter, after T iterations through the\n",
        "    feature matrix and the second element is a real number with the value of\n",
        "    theta_0, the offset classification parameter, after T iterations through\n",
        "    the feature matrix.\n",
        "    \"\"\"\n",
        "    theta = np.zeros(feature_matrix.shape[1], )\n",
        "    theta_0 = 0\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            theta, theta_0 = perceptron_single_step_update(feature_matrix[i], labels[i], theta, theta_0)\n",
        "            pass\n",
        "    return theta, theta_0\n",
        "   \n",
        "    raise NotImplementedError\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrUVKBmerp9Y"
      },
      "source": [
        "### 2.3 Average Perceptron\n",
        "\n",
        "The average perceptron will add a modification to the original perceptron algorithm: since the basic algorithm continues updating as the algorithm runs, nudging parameters in possibly conflicting directions, it is better to take an average of those parameters as the final answer. Every update of the algorithm is the same as before. The returned parameters θ, however, are an average of the θs across the nT steps:\n",
        "\n",
        "θ(final) =(1/nT)(θ(1)+θ(2)+...+θ(nT))\n",
        "\n",
        "Implemented the average perceptron algorithm. This function should be constructed similarly to the Full Perceptron Algorithm above, except that it should return the average values of θ and θo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFxakkfyrqHu"
      },
      "source": [
        "def average_perceptron(feature_matrix, labels, T):\n",
        "    \"\"\"\n",
        "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
        "\n",
        "\n",
        "    Args:\n",
        "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the perceptron algorithm\n",
        "            should iterate through the feature matrix.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    the average theta, the linear classification parameter, found after T\n",
        "    iterations through the feature matrix and the second element is a real\n",
        "    number with the value of the average theta_0, the offset classification\n",
        "    parameter, found after T iterations through the feature matrix.\n",
        "\n",
        "    Hint: It is difficult to keep a running average; however, it is simple to\n",
        "    find a sum and divide.\n",
        "    \"\"\"\n",
        "    theta = np.zeros(feature_matrix.shape[1], )\n",
        "    theta_0 = 0\n",
        "    theta_aggregate = np.zeros(feature_matrix.shape[1], )\n",
        "    theta_0_aggregate = 0\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            theta, theta_0 = perceptron_single_step_update(feature_matrix[i], labels[i], theta, theta_0)\n",
        "            theta_aggregate += theta\n",
        "            theta_0_aggregate += theta_0\n",
        "            pass\n",
        "    return theta_aggregate / (feature_matrix.shape[0] * T), theta_0_aggregate / (feature_matrix.shape[0] * T)\n",
        "    raise NotImplementedError\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46T8CPFksS3Y"
      },
      "source": [
        "# 3. Pegasos\n",
        "\n",
        "The following pseudo-code describes the Pegasos update rule.\n",
        "\n",
        "Pegasos update rule (x(i),y(i),λ,η,θ):\n",
        "\n",
        "if y(i)(θ⋅x(i))≤1 then\n",
        "  update θ=(1−ηλ)θ+ηy(i)x(i)\n",
        "else:\n",
        "  update θ=(1−ηλ)θ\n",
        "\n",
        "The η parameter is a decaying factor that will decrease over time. The λ parameter is a regularizing parameter.\n",
        "\n",
        "Adapted this update rule to add a bias term (θo) to the hypothesis, but take care not to penalize the magnitude of θo.\n",
        "\n",
        "\n",
        "### 3.1 Pegasos Single Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyc4cJxssTRu"
      },
      "source": [
        "def pegasos_single_step_update(\n",
        "        feature_vector,\n",
        "        label,\n",
        "        L,\n",
        "        eta,\n",
        "        current_theta,\n",
        "        current_theta_0):\n",
        "    \"\"\"\n",
        "    Properly updates the classification parameter, theta and theta_0, on a\n",
        "    single step of the Pegasos algorithm\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing a single data point.\n",
        "        label - The correct classification of the feature vector.\n",
        "        L - The lamba value being used to update the parameters.\n",
        "        eta - Learning rate to update parameters.\n",
        "        current_theta - The current theta being used by the Pegasos\n",
        "            algorithm before this update.\n",
        "        current_theta_0 - The current theta_0 being used by the\n",
        "            Pegasos algorithm before this update.\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta after the current update has completed and the second element is a\n",
        "    real valued number with the value of theta_0 after the current updated has\n",
        "    completed.\n",
        "    \"\"\"\n",
        "    if label * (np.dot(feature_vector, current_theta) + current_theta_0) <= 1:\n",
        "        theta_after_update = (1 - eta * L) * current_theta + label * eta * feature_vector\n",
        "        theta_0_after_update = current_theta_0 + label * eta\n",
        "        return theta_after_update, theta_0_after_update\n",
        "    else:\n",
        "        theta_after_update = (1 - eta * L) * current_theta\n",
        "        theta_0_after_update = current_theta_0\n",
        "        return theta_after_update, theta_0_after_update\n",
        "    raise NotImplementedErro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB6EGVUws7d3"
      },
      "source": [
        "### 3.2 Pegasos Full\n",
        "\n",
        "Given the same feature matrix and labels array as you were given in Full Perceptron Algorithm. Given T, the maximum number of times that you should iterate through the feature matrix before terminating the algorithm. Initialize θ and θ0 to zero. For each update, set η=1t√ where t is a counter for the number of updates performed so far (between 1 and nT inclusive). This function should return a tuple in which the first element is the final value of θ and the second element is the value of θ0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCNIzzvLs7oY"
      },
      "source": [
        "def pegasos(feature_matrix, labels, T, L):\n",
        "    \"\"\"\n",
        "    Runs the Pegasos algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    For each update, set learning rate = 1/sqrt(t),\n",
        "    where t is a counter for the number of updates performed so far (between 1\n",
        "    and nT inclusive).\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    Args:\n",
        "        feature_matrix - A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the algorithm\n",
        "            should iterate through the feature matrix.\n",
        "        L - The lamba value being used to update the Pegasos\n",
        "            algorithm parameters.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    the theta, the linear classification parameter, found after T\n",
        "    iterations through the feature matrix and the second element is a real\n",
        "    number with the value of the theta_0, the offset classification\n",
        "    parameter, found after T iterations through the feature matrix.\n",
        "    \"\"\"\n",
        "    theta = np.zeros(feature_matrix.shape[1], )\n",
        "    theta_0 = 0\n",
        "    n = 1\n",
        "    eta = 1\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            theta, theta_0 = pegasos_single_step_update(feature_matrix[i], labels[i], L, eta, theta, theta_0)\n",
        "            n += 1\n",
        "            eta = 1 / np.sqrt(n)\n",
        "    return theta, theta_0\n",
        "    raise NotImplementedError\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}